{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cf9693",
   "metadata": {},
   "source": [
    "### Data Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3c4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10ab3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_excel(\"C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/Input.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cb12fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2345.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-e-hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>432.0</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-telem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>50921.0</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>51382.8</td>\n",
       "      <td>https://insights.blackcoffer.com/coronavirus-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>51844.6</td>\n",
       "      <td>https://insights.blackcoffer.com/what-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>52306.4</td>\n",
       "      <td>https://insights.blackcoffer.com/marketing-dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>52768.2</td>\n",
       "      <td>https://insights.blackcoffer.com/continued-dem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      URL_ID                                                URL\n",
       "0      123.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "1      321.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "2     2345.0  https://insights.blackcoffer.com/rise-of-e-hea...\n",
       "3     4321.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "4      432.0  https://insights.blackcoffer.com/rise-of-telem...\n",
       "..       ...                                                ...\n",
       "109  50921.0  https://insights.blackcoffer.com/coronavirus-i...\n",
       "110  51382.8  https://insights.blackcoffer.com/coronavirus-i...\n",
       "111  51844.6  https://insights.blackcoffer.com/what-are-the-...\n",
       "112  52306.4  https://insights.blackcoffer.com/marketing-dri...\n",
       "113  52768.2  https://insights.blackcoffer.com/continued-dem...\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b691f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/My Solution/scraped-text/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91356104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract_new_layout():\n",
    "    input_df = pd.read_excel(r\"C:\\Users\\himan\\Coding\\Python\\NLP\\blackcoffer - assignment\\20211030 Test Assignment\\Input.xlsx\")\n",
    "    for fn in trange(len(input_df)):\n",
    "        url1 = input_df['URL'][fn]\n",
    "        r = requests.get(url1, headers={\"User-Agent\": \"ABC\"})\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        results = soup.find(class_ = 'td-post-content tagdiv-type')\n",
    "        if results is not None:\n",
    "            results = results.find_all('p')\n",
    "            title = soup.find_all(\"h1\", class_ = 'entry-title')\n",
    "            title = title[0].text\n",
    "            content = ''\n",
    "            for i in trange(len(results)):\n",
    "                content+=results[i].text + ' '\n",
    "            article = title + ' ' + content\n",
    "\n",
    "            with open(file+str(input_df['URL_ID'][fn])+'.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(article)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56060087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_extract_new_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bd3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract_from_old_layout():\n",
    "    input_df = pd.read_excel(r\"C:\\Users\\himan\\Coding\\Python\\NLP\\blackcoffer - assignment\\20211030 Test Assignment\\Input.xlsx\")\n",
    "    for fn in trange(len(input_df)):\n",
    "        url1 = input_df['URL'][fn]\n",
    "        r = requests.get(url1, headers={\"User-Agent\": \"ABC\"})\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        results = soup.find_all(class_ = 'tdb-block-inner td-fix-index')\n",
    "        if results is not None:\n",
    "            title = soup.find_all(\"h1\", class_='tdb-title-text')\n",
    "            if len(title)<=0:\n",
    "                continue\n",
    "            title = title[0].text\n",
    "            content = ''\n",
    "            #print(results)\n",
    "            results = results[14]\n",
    "            results = results.find_all('p')\n",
    "            for i in trange(len(results)):\n",
    "                content+=results[i].text + ' '\n",
    "            article = title + ' ' + content\n",
    "\n",
    "            with open(str(input_df['URL_ID'][fn]) + '.txt', 'w', encoding='utf-8') as f:\n",
    "                f.write(article)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c048251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_extract_from_old_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064abe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/'\n",
    "r = requests.get(url1, headers={\"User-Agent\": \"ABC\"})\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "results = soup.find_all(class_ = 'tdb-block-inner td-fix-index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "616e0b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"tdb-block-inner td-fix-index\">\n",
       "<p>2020 was the year the world was ravaged by the SarsCov2 virus. This notorious virus brought about a pandemic that would go on to change the course of humanity.  From that point forth daily lives of everyone across the world changed. With widespread stringent lockdowns, the entire world came to a sharp halt. Not only was the general populace affected, but the pandemic also affected all industries. The pandemic did not even spare critical industries, like healthcare and security. While these industries were required to function for the benefit of society, their daily operations changed drastically. But just as human nature prevails, we rose from this adversity. Post pandemic era saw the rise of new technologies that could aid overcome the restrictions put forth by the pandemic. In this article, we will specifically focus on the healthcare industries, innovations done in the industry, and the impact of those innovations on humans by 2030.</p>\n",
       "<p>Lockdowns initiated to curb the pandemic caused people to stay in their homes at all times. The exception to this was the medical staff who acted as our first line of defense against the pandemic. They not only had to deal with the pandemic but also had to cater to patients suffering from various other ailments. While people were restricted to go out, they still required medical consultation for their issues. This conundrum led to the rise of imparting healthcare facilities over electronic media. Healthcare workers utilized technologies such as video calls and virtual meetings to reach out to the needy. Now, these practices are also known as ‘e-Health’.  As the pandemic raged on, society saw numerous initiatives in the e-health sector. Government-led initiatives like ‘eSanjeevani OPD’ brought government OPD facilities directly to people’s homes.  It should be noted that e-health is not just limited to providing patients with virtual meetings. It encompasses every technology that transitions the traditional healthcare sector into a more accessible electronic form. Keeping with this trend we also saw the use of the Internet of Things (IoT)  to build the Internet of Medical Things (IoMT). These internet-connected devices allowed remote monitoring and controlling of facilities imparted to patients.  With the onset of 5G technology, the use of  IoMT has flourished. Some of these solutions include smart devices that monitor an individual’s health metrics. These devices are also capable of sending out alerts in case the metrics do not fall under the acceptable range. Furthermore with the advancements in artificial intelligence, machine learning, and deep learning technologies these devices do more than just report. With the help of these technologies, IoMT devices are now capable of intelligently performing actions that keep the metric of a patient in check.</p>\n",
       "<p>Another interesting technology that has found its use in the healthcare industry is ‘Blockchain technology. The technology used as the base for cryptocurrency can also be used to maintain immutable records of patients. Such blockchain solutions are already finding their way into the market Pranacare, is one such India start-up. It is a  platform for doctors driven by blockchain and AI. It offers tools to help dieticians, diabetologists, and cardiac specialists manage their customers and data. It also maintains, tracks, and records patient data and offers a decentralized ledger. The armchair is another organization that combines blockchain technology and the health industry.  The armchair provides an Ethereum-based platform for electronic health records storage. The blockchain is a hybrid public/private network that analyses data using Artificial Intelligence. Will use Ethereum Smart Contracts with the Hyperledger Sawtooth platform to offer a safe method for both patients and providers to access patient data. Existing e-health services also saw a rise during the pandemic. For example, telemedicine visits increased from 1-2% of ambulatory care visits before to the pandemic to 30% of all visits. With customer readiness to adopt telehealth climbing to 66%. According to health systems, up to 40% of primary care appointments might be performed remotely.</p>\n",
       "<p>With the increased penetration of the internet in our daily lives, it has been now critical for companies and start-ups to capture this segment. Keeping in with this agenda, the market has seen a proliferation of companies providing e-health services. Consequently, this industry has also seen an increase.in investments. Between 2019 and 2020, investments in telemedicine solutions quadrupled, rising from $1.1 billion to $3.1 billion. In 2020, total funding for remote patient monitoring (RPM) solutions will have more than quadrupled, rising from $417 million to $941 million. According to e-healthcare investors, RPM solutions for chronic care management are expected to become more popular in the next coming years. Analysts predict that eHealth will increase at a compound annual growth rate of 16.1% from 2022 to 2030, with the eHealth segment expected to generate $61.4 billion in sales in 2023 alone. China is expected to lead the global market followed by the USA. Overall, the e-Health industry is expected to see a boom in investments, providing early investors with a large return for their investments.</p>\n",
       "<p>While e-Health seems like the probable future for the entire healthcare industry, special attention must be given to the security aspect of these services. Being connected to the internet and being made available to all also attracts a lot of nefarious elements. Cybercriminals continually target the healthcare industry. The ransomware attack on AIIMS New Delhi is a prime example of this. Cybercriminals were able to cripple AIIMS systems. For over two weeks this caused massive chaos and confusion among the general public. The pandemic itself saw a large number of healthcare-themed smishing and vishing attacks. Their major motive was to exploit the insecure and scared public and make use of the pandemic to extort money. Every example of a cyberattack on a healthcare industry has always led to massive chaos. Healthcare is considered a critical industry, thereby it needs to be adequately protected. With e-Health on the rise, by 2023 society can also expect a lot of jobs to open in the sector of cyber security in the healthcare industry.</p>\n",
       "<p>e-Health solutions are the need of the hour. Integrating e-Health solutions with up-and-coming technologies can effectively ensure inclusivity for all. Such solutions can bring healthcare facilities to the remotest parts of the earth. With current trends in sight, 2030 is expected to have a large market share occupied by e-Health solutions. Early investors can expect high returns by 2030. With this in mind, special focus should also be given to securing the ever-growing e-health industry.</p>\n",
       "<pre class=\"wp-block-preformatted\">Blackcoffer Insights 46: Aparajita Thakur, Jesus And Mary College , University Of Delhi</pre>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbdad844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_file_names(folder_path):\n",
    "    file_names = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "            file_names.append(filename)\n",
    "    return file_names\n",
    "\n",
    "folder_path = 'C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/My Solution/scraped-text/'\n",
    "file_names = get_file_names(folder_path)\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for filename in file_names:\n",
    "    all_files.append(float(filename[:-4]))\n",
    "    #print(filename[:-4])\n",
    "    \n",
    "len(input_df) - len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b3e42f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_df['URL_ID'].tolist()[0])\n",
    "type(all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a28cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11668.0\n",
      "17671.4\n"
     ]
    }
   ],
   "source": [
    "for el in (input_df['URL_ID'].tolist()):\n",
    "    if el not in all_files:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a9d8e",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb7e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55993d",
   "metadata": {},
   "source": [
    "#### Extracting Stop Words, Positive and Negative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0859a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7291e2e69e9416498590fbd5e07e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = []\n",
    "for lst in tqdm(os.listdir('C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/StopWords')):\n",
    "    with open(f'C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/StopWords/{lst}', 'r', encoding = 'latin-1') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = ''.join(line[:-1].split(' '))\n",
    "        words = line.split('|')\n",
    "        stop_words += words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14169982",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "with open('C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/MasterDictionary/positive-words.txt', 'r') as f:\n",
    "    words = f.readlines()\n",
    "f.close()\n",
    "for word in words:\n",
    "    word = word[:-1]\n",
    "    positive_words += [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4012470",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = []\n",
    "with open('C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/MasterDictionary/negative-words.txt', 'r') as f:\n",
    "    words = f.readlines()\n",
    "f.close()\n",
    "for word in words:\n",
    "    word = word[:-1]\n",
    "    negative_words += [word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37192040",
   "metadata": {},
   "source": [
    "#### Removing duplicate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2621bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(set(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaadd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703fd75",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50deddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n",
    "def preprocessing(article):\n",
    "    lem_words = []\n",
    "    words = []\n",
    "    word_tokens = word_tokenize(article)\n",
    "    for word in word_tokens:\n",
    "        word = word.rstrip()\n",
    "        word = word.lower()\n",
    "        word = ''.join(re.findall('[a-zA-Z0-9]', word))\n",
    "        tag = pos_tagger(nltk.pos_tag([word])[0][1])\n",
    "        lem = WordNetLemmatizer()\n",
    "        if word not in stop_words:\n",
    "            if tag is None:\n",
    "                lem_words.append(word) \n",
    "            else:\n",
    "                lem_words.append(lem.lemmatize(word, tag)) \n",
    "        if word not in nltk_stopwords:\n",
    "            if tag is None:\n",
    "                words.append(word) \n",
    "            else:\n",
    "                words.append(lem.lemmatize(word, tag)) \n",
    "\n",
    "    return lem_words, words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911ce92",
   "metadata": {},
   "source": [
    "#### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b956690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(words): # Returns positive score, negative score, polarity score, subjectivity score\n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    for word in words:\n",
    "        if word in positive_words:\n",
    "            pos_score += 1\n",
    "        elif word in negative_words:\n",
    "            neg_score += -1\n",
    "\n",
    "    neg_score *= -1\n",
    "    \n",
    "    \n",
    "    return pos_score, neg_score, (pos_score - neg_score) / (pos_score + neg_score) + 0.000001, (pos_score + neg_score) / len(words) + 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "969f7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables(words):\n",
    "    return [word.count('a') + word.count('e') + word.count('i') + word.count('o') + word.count('u') if word[:-2] not in ['es', 'ed']  else word.count('a') + word.count('i') + word.count('o') + word.count('u') for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ecfa3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_len(words):\n",
    "    lens = np.array([len(word) for word in words])\n",
    "    return np.sum(lens) / len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31da62d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_personal_pronouns(words):\n",
    "    sent = ' '.join(words)\n",
    "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "    pronouns = pronounRegex.findall(sent)\n",
    "    return len(pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60cda25",
   "metadata": {},
   "source": [
    "#### Running the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62489f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_excel('C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/Output Data Structure.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "597a094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df.set_index('URL_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f1aecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7098f4eab2a14d719900a98266c35a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for article_id in tqdm(os.listdir('C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/My Solution/scraped-text/')):\n",
    "    with open(f'C:/Users/himan/Coding/Python/NLP/blackcoffer - assignment/20211030 Test Assignment/My Solution/scraped-text/{article_id}', 'r', encoding='utf-8') as f:\n",
    "        article = f.readlines()\n",
    "    f.close()\n",
    "    id = float(article_id[:-4])\n",
    "    article = ' '.join(article)\n",
    "    sent_tokens = sent_tokenize(article)\n",
    "    word_tokens = word_tokenize(article)\n",
    "    output_df.at[id, 'AVG NUMBER OF WORDS PER SENTENCE'] = output_df.at[id, 'AVG SENTENCE LENGTH'] = len(word_tokens) / len(sent_tokens)\n",
    "    clean_lemwords, clean_words = preprocessing(article)\n",
    "    output_df.at[id, 'POSITIVE SCORE'], output_df.at[id, 'NEGATIVE SCORE'], output_df.at[id, 'POLARITY SCORE'], output_df.at[id, 'SUBJECTIVITY SCORE'] = sentiment_scores(clean_lemwords)\n",
    "    output_df.at[id, 'WORD COUNT'] = len(clean_words)\n",
    "    syllable_lst = np.array(syllables(clean_words))\n",
    "    output_df.at[id, 'SYLLABLE PER WORD'] = np.sum(syllable_lst)/len(syllable_lst)\n",
    "    output_df.at[id, 'COMPLEX WORD COUNT'] = len(np.where(syllable_lst>2)[0])\n",
    "    output_df.at[id, 'PERCENTAGE OF COMPLEX WORDS'] = output_df.at[id, 'COMPLEX WORD COUNT']/output_df.at[id, 'WORD COUNT']\n",
    "    output_df.at[id, 'FOG INDEX'] = 0.4*(output_df.at[id, 'AVG SENTENCE LENGTH'] + output_df.at[id, 'PERCENTAGE OF COMPLEX WORDS'])\n",
    "    output_df.at[id, 'AVG WORD LENGTH'] = avg_word_len(clean_words)\n",
    "    output_df.at[id, 'PERSONAL PRONOUNS'] = num_personal_pronouns(clean_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f83ba1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_excel('Output.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
